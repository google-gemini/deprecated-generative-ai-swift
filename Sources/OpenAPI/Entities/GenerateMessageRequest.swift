// Generated by Create API
// https://github.com/CreateAPI/CreateAPI
//
// Copyright 2023 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//    http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

import Foundation

/// Request to generate a message response from the model.
public struct GenerateMessageRequest: Codable {
  /// Optional. The maximum number of tokens to consider when sampling. The model uses combined Top-k and nucleus sampling. Top-k sampling considers the set of `top_k` most probable tokens.
  public var topK: Int32?
  /// Optional. The maximum cumulative probability of tokens to consider when sampling. The model uses combined Top-k and nucleus sampling. Nucleus sampling considers the smallest set of tokens whose probability sum is at least `top_p`.
  public var topP: Float?
  /// Optional. The number of generated response messages to return. This value must be between `[1, 8]`, inclusive. If unset, this will default to `1`.
  public var candidateCount: Int32?
  /// All of the structured input text passed to the model as a prompt. A `MessagePrompt` contains a structured set of fields that provide context for the conversation, examples of user input/model output message pairs that prime the model to respond in different ways, and the conversation history or list of messages representing the alternating turns of the conversation between the user and the model.
  public var prompt: MessagePrompt?
  /// Optional. Controls the randomness of the output. Values can range over `[0.0,1.0]`, inclusive. A value closer to `1.0` will produce responses that are more varied, while a value closer to `0.0` will typically result in less surprising responses from the model.
  public var temperature: Float?

  public init(topK: Int32? = nil, topP: Float? = nil, candidateCount: Int32? = nil, prompt: MessagePrompt? = nil, temperature: Float? = nil) {
    self.topK = topK
    self.topP = topP
    self.candidateCount = candidateCount
    self.prompt = prompt
    self.temperature = temperature
  }

  public init(from decoder: Decoder) throws {
    let values = try decoder.container(keyedBy: StringCodingKey.self)
    self.topK = try values.decodeIfPresent(Int32.self, forKey: "topK")
    self.topP = try values.decodeIfPresent(Float.self, forKey: "topP")
    self.candidateCount = try values.decodeIfPresent(Int32.self, forKey: "candidateCount")
    self.prompt = try values.decodeIfPresent(MessagePrompt.self, forKey: "prompt")
    self.temperature = try values.decodeIfPresent(Float.self, forKey: "temperature")
  }

  public func encode(to encoder: Encoder) throws {
    var values = encoder.container(keyedBy: StringCodingKey.self)
    try values.encodeIfPresent(topK, forKey: "topK")
    try values.encodeIfPresent(topP, forKey: "topP")
    try values.encodeIfPresent(candidateCount, forKey: "candidateCount")
    try values.encodeIfPresent(prompt, forKey: "prompt")
    try values.encodeIfPresent(temperature, forKey: "temperature")
  }
}
